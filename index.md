# Data Description
The primary goal of the research I am conducting is to validate a simplified model of heat transfer coefficients from boiling surfaces, with an emphasis on dielectric (non-conductive) fluids. For context, the majority of data centers around the world are primarily air cooled, and the lack of liquid cooling represents a relatively large inefficiency. Even without extensive knowledge of heat transfer, nearly everyone can identify a significant temperature difference between standing in a 70℉ room and swimming in a 70℉ pool. It happens that boiling the fluid enhances this perceived heat transfer by yet another order of magnitude. By then immersing computer processors in a fluid whose boiling point is near that of the ideal operating temperature of the processor, significant efficiency gains could be seen in cooling requirements for data centers. By studying certain behaviors of fluid flow in and around boiling surfaces we can validate a model which would allow the optimization of board design with respect to cooling capabilities much easier.  

 Obviously, the idea of immersion cooling computer components has been around for some time, however the current scaled application of immersion cooled, ie. data centers, only immerse circuit boards that have been designed and optimized for air cooling. In my research we utilize a technique known as Particle Image Velocimetry (PIV) wherein a fluorescent particle, referred to as a ‘tracer’ is injected into a fluid to be studied. A planar laser is then flashed and a single image is captured, when done in succession quickly, the resulting images will create a film with the tracers highlighting the fluid streamlines. THe resulting images are then fed into a code that creates a 3-D vector map of fluid velocities on and around the surface, which is saved as a 3-D model. The hope is that by using this technique on a boiling surface we can validate a previously postulated, simplified hydrodynamic model of a certain boiling phenomenon which would greatly improve the ability to optimize data center immersion cooling, and thus the total efficiency. 

I have not yet begun to take PIV data as I am still getting the experimental enclosure operational, however I have talked with some peers who knew previous students with PIV experiments. From my understanding one PIV project required an entire harddrive only a few years ago, so I am projecting to need at least a 1 TB of space. This is mainly to do with the hundreds of thousands if not millions of photos that need to be taken in order to get images that the MatLab code can properly parse into a vector field. 


# Roles and responsibilities

# Data standards and metadata
# Storage and security
# Access and data sharing
# Archiving and preservation
